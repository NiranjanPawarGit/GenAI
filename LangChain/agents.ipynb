{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6316b264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from duckduckgo-search) (8.1.8)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
      "  Downloading primp-0.15.0-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search)\n",
      "  Downloading lxml-6.0.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\niran\\appdata\\roaming\\python\\python310\\site-packages (from click>=8.1.8->duckduckgo-search) (0.4.6)\n",
      "Downloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Downloading lxml-6.0.0-cp310-cp310-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 929.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 929.6 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.8/4.0 MB 838.9 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 931.8 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.3/4.0 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 1.3/4.0 MB 1.0 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.6/4.0 MB 953.2 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.8/4.0 MB 986.7 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.1/4.0 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.6/4.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.1/4.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.4/4.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/4.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading primp-0.15.0-cp38-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.0/3.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.3/3.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.6/3.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.8/3.1 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.4/3.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.9/3.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: primp, lxml, duckduckgo-search\n",
      "\n",
      "   ------------- -------------------------- 1/3 [lxml]\n",
      "   ------------- -------------------------- 1/3 [lxml]\n",
      "   ------------- -------------------------- 1/3 [lxml]\n",
      "   -------------------------- ------------- 2/3 [duckduckgo-search]\n",
      "   ---------------------------------------- 3/3 [duckduckgo-search]\n",
      "\n",
      "Successfully installed duckduckgo-search-8.1.1 lxml-6.0.0 primp-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U duckduckgo-search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e811fb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LOKALAFDELINGER ARSENAL FC er en af Englands største og mest vindende fodboldklubber. En historie, der rækker mere end 100 år tilbage, har ført stribevis af … Arsenal Denmark gør opmærksom på, at der ikke er fortrydelsesret på indmeldelse i foreningen, og at betaling af kontingentet således ikke kan fortrydes eller kræves … Arsenals hjemmebanetrøje for sæsonen 2025/26 hylder klubbens stolte tradition med den klassiske røde overdel og de skinnende hvide ærmer. Logoet er holdt i rene … Tilmeldelse af Arsenal Denmarks nyhedsbrev med mange vigtige oplysninger, datoer og invitationer. Hvor mange lod du som medlem har forud for vores billettrækningsvindue i … Jan 8, 2024 · Transfervinduet er atter åbent, hvorfor vi i følgende artikel vil dykke ned i de mulige til- og afgange, vi kan se nærmere på for Mikel Artetas mandskab. Arsenal er efter …'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "search.run(\"arsenal vs psg match summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b23c28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:\n",
      " [\"echo 'Hello World!'\", 'time']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\tools\\shell\\tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import ShellTool\n",
    "\n",
    "shell_tool = ShellTool()\n",
    "result = shell_tool.run({\"commands\": [\"echo 'Hello World!'\", \"time\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb6bbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\AppData\\Local\\Temp\\ipykernel_23516\\3666644574.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama2\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e38086a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The word \"educá\" has 8 letters.', additional_kwargs={}, response_metadata={'model': 'llama2', 'created_at': '2025-07-30T01:38:43.6900284Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 9433078700, 'load_duration': 5682700300, 'prompt_eval_count': 29, 'prompt_eval_duration': 2431197400, 'eval_count': 13, 'eval_duration': 1312037900}, id='run--f0010e1c-138c-45e2-becc-b96260d2654c-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how many letters in the word educa?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342331bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str):\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f4b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a very powerful assistant but not great at calculating word lengths.\",\n",
    "\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64453c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool='get_weather' tool_input={'location': 'New York'} log='Action: get_weather\\nAction Input: { \"location\": \"New York\" }'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents.format_scratchpad import format_to_tool_messages\n",
    "from langchain.agents import AgentOutputParser\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.tools import tool\n",
    "import json\n",
    "\n",
    "# --- Define a simple tool ---\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is sunny.\"\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "# Create a string describing the tools for the prompt\n",
    "tool_descs = \"\\n\".join([f\"{t.name}: {t.description}\" for t in tools])\n",
    "\n",
    "# --- Custom Output Parser ---\n",
    "class SimpleToolOutputParser(AgentOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        if \"Action:\" in text:\n",
    "            try:\n",
    "                action_name = text.split(\"Action:\")[1].split(\"\\n\")[0].strip()\n",
    "                action_input_str = text.split(\"Action Input:\")[1].strip()\n",
    "                try:\n",
    "                    action_input = json.loads(action_input_str)\n",
    "                except:\n",
    "                    action_input = {\"input\": action_input_str}\n",
    "                return AgentAction(tool=action_name, tool_input=action_input, log=text)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Could not parse tool action: {text}\") from e\n",
    "        else:\n",
    "            return AgentFinish(return_values={\"output\": text.strip()}, log=text)\n",
    "\n",
    "# --- Prompt Template ---\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     f\"You are a helpful AI assistant. You have access to the following tools:\\n\\n{tool_descs}\\n\\n\"\n",
    "     \"When you want to use a tool, reply in the following format:\\n\"\n",
    "     \"Action: <tool name>\\n\"\n",
    "     \"Action Input: <JSON input>\\n\\n\"\n",
    "     \"When you want to give the final answer, just reply with it directly.\"\n",
    "    ),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "# --- Initialize Ollama model ---\n",
    "llm = ChatOllama(model=\"llama2\", temperature=0)\n",
    "\n",
    "# --- Agent chain ---\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_tool_messages(x[\"intermediate_steps\"]),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | SimpleToolOutputParser()\n",
    ")\n",
    "\n",
    "# --- Test the agent ---\n",
    "result = agent.invoke({\n",
    "    \"input\": \"What's the weather in New York?\",\n",
    "    \"intermediate_steps\": []\n",
    "})\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaaf254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a very powerful assistant but not great at calculating word lengths.\",\n",
    "            \n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c95382e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bd9160a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm_with_tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      2\u001b[0m     {\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: format_to_openai_function_messages(\n\u001b[0;32m      5\u001b[0m             x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m         ),\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m     }\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;241m|\u001b[39m \u001b[43mllm_with_tools\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIFunctionsAgentOutputParser()\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm_with_tools' is not defined"
     ]
    }
   ],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de00ec2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_executor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow many letters in the word educa?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent_executor\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: input1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_history})\n\u001b[0;32m      3\u001b[0m chat_history\u001b[38;5;241m.\u001b[39mextend([\n\u001b[0;32m      4\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39minput1),\n\u001b[0;32m      5\u001b[0m     AIMessage(content\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m      6\u001b[0m ])\n\u001b[0;32m      7\u001b[0m agent_executor\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis that a real word?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_history})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_executor' is not defined"
     ]
    }
   ],
   "source": [
    "input1 = \"how many letters in the word educa?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=input1),\n",
    "    AIMessage(content=result[\"Output\"]),\n",
    "])\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee045fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.177.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-python-client) (2.37.0)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (6.31.1)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2024.12.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\niran\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Downloading google_api_python_client-2.177.0-py3-none-any.whl (13.7 MB)\n",
      "   ---------------------------------------- 0.0/13.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/13.7 MB 2.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.6/13.7 MB 2.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/13.7 MB 2.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.6/13.7 MB 2.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.1/13.7 MB 2.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.9/13.7 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.5/13.7 MB 2.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.0/13.7 MB 2.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.8/13.7 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.3/13.7 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.8/13.7 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.6/13.7 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.1/13.7 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.7/13.7 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.7/13.7 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.2/13.7 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.0/13.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.8/13.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.6/13.7 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.1/13.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.7/13.7 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: uritemplate, proto-plus, httplib2, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "\n",
      "   ------ --------------------------------- 1/6 [proto-plus]\n",
      "   ------ --------------------------------- 1/6 [proto-plus]\n",
      "   ------------- -------------------------- 2/6 [httplib2]\n",
      "   -------------------------- ------------- 4/6 [google-api-core]\n",
      "   -------------------------- ------------- 4/6 [google-api-core]\n",
      "   -------------------------- ------------- 4/6 [google-api-core]\n",
      "   -------------------------- ------------- 4/6 [google-api-core]\n",
      "   -------------------------- ------------- 4/6 [google-api-core]\n",
      "   --------------------------------- ------ 5/6 [google-api-python-client]\n",
      "   --------------------------------- ------ 5/6 [google-api-python-client]\n",
      "   --------------------------------- ------ 5/6 [google-api-python-client]\n",
      "   --------------------------------- ------ 5/6 [google-api-python-client]\n",
      "   --------------------------------- ------ 5/6 [google-api-python-client]\n",
      "   ---------------------------------------- 6/6 [google-api-python-client]\n",
      "\n",
      "Successfully installed google-api-core-2.25.1 google-api-python-client-2.177.0 google-auth-httplib2-0.2.0 httplib2-0.22.0 proto-plus-1.26.1 uritemplate-4.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\niran\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\niran\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\utils\\_process_win32.py:124: ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "  return process_handler(cmd, _system_body)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b3f77c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\AppData\\Local\\Temp\\ipykernel_23516\\2298691558.py:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.7)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0.7, 'mod...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain, SequentialChain\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[1;32m----> 5\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m synopsis_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTitle: \u001b[39m\u001b[38;5;132;01m{title}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEra: \u001b[39m\u001b[38;5;132;01m{era}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlaywright: This is a synopsis for the above play:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m synopsis_prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate(input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera\u001b[39m\u001b[38;5;124m\"\u001b[39m], template\u001b[38;5;241m=\u001b[39msynopsis_template)\n",
      "File \u001b[1;32mc:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:222\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     emit_warning()\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\niran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0.7, 'mod...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(temperature=0.7)\n",
    "synopsis_template = \"You are a playwright. Given the title of play and the era it is set in, it is your job to write a synopsis for that title.\\n\\nTitle: {title}\\nEra: {era}\\nPlaywright: This is a synopsis for the above play:\"\n",
    "synopsis_prompt_template = PromptTemplate(input_variables=[\"title\", \"era\"], template=synopsis_template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=synopsis_prompt_template, output_keys=\"synopsis\")\n",
    "\n",
    "review_template = \"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\\n\\nPlay Synopsis:\\n{synopsis}\\nReview from a New York Times play critic of the above play:\"\n",
    "prompt_template = PromptTemplate(inpput_variables = [\"synopsis\"], template=review_template)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"review\")\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[synopsis_chain, review_chain],\n",
    "    input_variables=[\"era\", \"title\"],\n",
    "    output_variables=[\"synopsis\", \"review\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "overall_chain({\"title\": \"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66866ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'synopsis_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate(input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynopsis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m], template\u001b[38;5;241m=\u001b[39mtemplate)\n\u001b[0;32m      8\u001b[0m social_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt_template, output_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocial_post_text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m overall_chain \u001b[38;5;241m=\u001b[39m SequentialChain(\n\u001b[0;32m     11\u001b[0m     memory\u001b[38;5;241m=\u001b[39mSimpleMemory(memories\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecember 25th, * pm PST\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTheater in the Park\u001b[39m\u001b[38;5;124m\"\u001b[39m}),\n\u001b[1;32m---> 12\u001b[0m     chains\u001b[38;5;241m=\u001b[39m[\u001b[43msynopsis_chain\u001b[49m, review_chain, social_chain],\n\u001b[0;32m     13\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     14\u001b[0m     output_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocial_post_text\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )    \n\u001b[0;32m     17\u001b[0m overall_chain({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTragedy at sunset on the beach\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVictorian England\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'synopsis_chain' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.memory import SimpleMemory\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "template = \"You are a social media manager for a theater company. Given the title of play, the era it is set in, the date, time and location, the synopsis of the play, and the review of the play,\\\n",
    "    it is your job to write a social media post for that play.\\n\\nHere is some context about the time and location of the play:\\nDate and Time: {time}\\nLocation: {location}\\n\\nPlay Synopsis:\\n{synopsis}\\nReview from a New York Times play critic of the above play:\\n{review}\\n\\nSocial Media Post:\"\n",
    "    \n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\", \"review\", \"time\", \"location\"], template=template)\n",
    "social_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"social_post_text\")\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    memory=SimpleMemory(memories={\"time\": \"December 25th, * pm PST\", \"location\": \"Theater in the Park\"}),\n",
    "    chains=[synopsis_chain, review_chain, social_chain],\n",
    "    input_variables=[\"era\", \"title\"],\n",
    "    output_variables=[\"social_post_text\"],\n",
    "    verbose=True\n",
    ")    \n",
    "overall_chain({\"title\": \"Tragedy at sunset on the beach\", \"era\": \"Victorian England\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f8b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
